{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, classes):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(data, dtype=torch.float)\n",
    "        self.classes = torch.tensor(classes, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.classes[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path: str, train_classes_path: str, test_path: str, test_classes_path: str,\n",
    "                 batch_size: int = 1):\n",
    "        super().__init__()\n",
    "        self.train_path = train_path\n",
    "        self.train_classes_path = train_classes_path\n",
    "        self.test_path = test_path\n",
    "        self.test_classes_path = test_classes_path\n",
    "\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.train_classes = None\n",
    "        self.test_classes = None\n",
    "        self.sep = ';'\n",
    "        self.num_classes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.vector_len = None\n",
    "\n",
    "        self.prepare_data()\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(text_tensor, total):\n",
    "        n = total - len(text_tensor)\n",
    "        return F.pad(text_tensor, (0, n))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.download_dataset()\n",
    "        self.num_classes = len(set(self.train_classes))\n",
    "\n",
    "    def download_dataset(self):\n",
    "        with open(self.train_path) as f:\n",
    "            self.train_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.test_path) as f:\n",
    "            self.test_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.train_classes_path) as f:\n",
    "            self.train_classes = [int(line) - 1 for line in f]\n",
    "        with open(self.test_classes_path) as f:\n",
    "            self.test_classes = [int(line) - 1 for line in f]\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.vector_len = self.count_vector_len()\n",
    "        self.train_data = [i + [0] * (self.vector_len - len(i)) for i in self.train_data]\n",
    "        self.test_data = [i + [0] * (self.vector_len - len(i)) for i in self.test_data[:self.vector_len]]\n",
    "        self.train_dataset = MyDataset(data=self.train_data, classes=self.train_classes)\n",
    "        self.test_dataset = MyDataset(data=self.test_data, classes=self.test_classes)\n",
    "\n",
    "    def count_vector_len(self):\n",
    "        max_len = 0\n",
    "        for vector in self.train_data:\n",
    "            max_len = max(max_len, len(vector))\n",
    "        return max_len\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def num_inputs(self):\n",
    "        if not self.vector_len:\n",
    "            self.vector_len = self.count_vector_len()\n",
    "        return self.vector_len\n",
    "\n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        return self.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "import snntorch as snn\n",
    "import torch.nn.functional as F\n",
    "from snntorch import surrogate\n",
    "import snntorch.functional as SF\n",
    "\n",
    "\n",
    "\n",
    "class SpikeText(pl.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, beta, num_outputs, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.spike_grad = surrogate.fast_sigmoid()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=self.spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        # Initialize hidden states at t=0\n",
    "        self.mem1 = self.lif1.init_leaky()\n",
    "        self.lr = learning_rate\n",
    "        # self.loss_fct = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x, mem1):\n",
    "        cur1 = self.fc1(x)\n",
    "        spk1, mem1_after = self.lif1(cur1, mem1)\n",
    "        cur2 = self.fc2(spk1)\n",
    "        return cur2, mem1_after\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     spk, mem = self.forward(x)\n",
    "    #     loss = self.loss_fct(mem, y)\n",
    "    #     self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    #     return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "ib_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIBClass.csv'\n",
    "    )\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleBClass.csv'\n",
    "    )\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydateClass.csv'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "model_ng = SpikeText(num_inputs=ng_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                  num_outputs=ng_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_ib = SpikeText(num_inputs=ib_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                  num_outputs=ib_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_b = SpikeText(num_inputs=b_data_module.num_inputs, num_hidden=1000, beta=0.85,\n",
    "                  num_outputs=b_data_module.num_outputs, learning_rate=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "ib_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])\n",
    "b_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])\n",
    "ng_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 20.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e5d3b3ea609486785003f7a6c948fb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa6d136914364e47a2031e35dbd6e4ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42d8e557b91744208ea11789165a02d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_sets = [(model_ng, ng_data_module, ng_trainer), (model_b, b_data_module, b_trainer), (model_ib, ib_data_module, ib_trainer)]\n",
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cf15cf5b5f24c0aae1323fcd09da0d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.08134832233190536, 'test_loss': 4.655596733093262}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcbb80f6b6bf48da97e827abfba928f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3523232638835907, 'test_loss': 2.026945114135742}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b22b477a0e0d452dadea89dd433a193d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3480547368526459, 'test_loss': 2.051805257797241}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.test(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "class Perceptron(pl.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, learning_rate):\n",
    "        super().__init__()\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lr = learning_rate\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        cur1 = self.fc1(x)\n",
    "        cur2 = self.fc2(cur1)\n",
    "        return cur2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "ib_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshIB/TestTitleIBClass.csv'\n",
    "    )\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/TitleMeshB/TestTitleBClass.csv'\n",
    "    )\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='/Users/wojciechsitek/Documents/Indexing/code/indexingcode/data/DatasetsPM/20NewsgroupShort/TestShortBydateClass.csv'\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | fc2            | Linear   | 20.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41c132f107f34689ad5c9e18773989b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dbde116ed474a9fa1e9692cba7f50d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.006094762589782476, 'test_loss': 4.882161617279053}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65a71235214e44f3af35baa46b24d413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "320811e37de446ce957f2cae5e8d673e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3267398178577423, 'test_loss': 2.287667751312256}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83abbffedd164ca1a5d2beb15f1b7052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ff46252e755417087aee3f822bfc3e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.36403772234916687, 'test_loss': 2.2534267902374268}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ng_mlp_model = Perceptron(num_inputs=ng_data_module.num_inputs, num_hidden=1000,\n",
    "                  num_outputs=ng_data_module.num_outputs, learning_rate=1e-4)\n",
    "ib_mlp_model = Perceptron(num_inputs=ib_data_module.num_inputs, num_hidden=1000,\n",
    "                  num_outputs=ib_data_module.num_outputs, learning_rate=1e-4)\n",
    "b_mlp_model = Perceptron(num_inputs=b_data_module.num_inputs, num_hidden=1000,\n",
    "                  num_outputs=b_data_module.num_outputs, learning_rate=1e-4)\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")\n",
    "mlp_trainer_ib = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])\n",
    "mlp_trainer_b = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])\n",
    "mlp_trainer_ng = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                     max_epochs=5, gpus=torch.cuda.device_count(),\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "mlp_training_sets = [(ng_mlp_model, ng_data_module, mlp_trainer_ng), (ib_mlp_model, ib_data_module, mlp_trainer_ib), (b_mlp_model, b_data_module, mlp_trainer_b)]\n",
    "\n",
    "for mlp_model, mlp_data_module, mlp_trainer in mlp_training_sets:\n",
    "    mlp_trainer.fit(mlp_model, datamodule=mlp_data_module)\n",
    "    mlp_trainer.test(mlp_model, datamodule=mlp_data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7532, 751]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-93-5d592bc390d1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"RESULT:\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0marray\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \"\"\"\n\u001B[0;32m---> 84\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m             \u001B[0;34m%\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [7532, 751]"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "    X = data_module.train_data\n",
    "    y = data_module.train_classes\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    pred = clf.predict(data_module.test_data)\n",
    "    print(\"RESULT:\",accuracy_score(data_module.test_classes, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "751"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ng_data_module.test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7532, 751]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-94-3270499be34f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mlrcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mlrcv_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlrcv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"RESULT:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_module\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_classes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlrcv_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0marray\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mindicator\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \"\"\"\n\u001B[0;32m---> 84\u001B[0;31m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m     \u001B[0mtype_true\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0mtype_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_of_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/anaconda3/envs/indexing/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 332\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    333\u001B[0m             \u001B[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    334\u001B[0m             \u001B[0;34m%\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [7532, 751]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "# for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "data_module = ng_data_module\n",
    "X = data_module.train_data\n",
    "y = data_module.train_classes\n",
    "lrcv = LogisticRegressionCV()\n",
    "lrcv.fit(X, y)\n",
    "lrcv_pred = lrcv.predict(data_module.test_data)\n",
    "print(\"RESULT:\", accuracy_score(data_module.test_classes, lrcv_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}