{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, classes):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(data, dtype=torch.float)\n",
    "        self.classes = torch.tensor(classes, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.classes[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path: str, train_classes_path: str, test_path: str, test_classes_path: str,\n",
    "                 batch_size: int = 1):\n",
    "        super().__init__()\n",
    "        self.train_path = train_path\n",
    "        self.train_classes_path = train_classes_path\n",
    "        self.test_path = test_path\n",
    "        self.test_classes_path = test_classes_path\n",
    "\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.train_classes = None\n",
    "        self.test_classes = None\n",
    "        self.sep = ';'\n",
    "        self.num_classes = None\n",
    "        self.batch_size = batch_size\n",
    "        self.vector_len = None\n",
    "\n",
    "        self.prepare_data()\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(text_tensor, total):\n",
    "        n = total - len(text_tensor)\n",
    "        return F.pad(text_tensor, (0, n))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.download_dataset()\n",
    "        self.num_classes = len(set(self.train_classes))\n",
    "\n",
    "    def download_dataset(self):\n",
    "        with open(self.train_path) as f:\n",
    "            self.train_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.test_path) as f:\n",
    "            self.test_data = [[float(_) for _ in line.split(self.sep)] for line in f]\n",
    "        with open(self.train_classes_path) as f:\n",
    "            self.train_classes = [int(line) - 1 for line in f]\n",
    "        with open(self.test_classes_path) as f:\n",
    "            self.test_classes = [int(line) - 1 for line in f]\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.vector_len = self.count_vector_len()\n",
    "        self.train_data = [i + [0] * (self.vector_len - len(i)) for i in self.train_data]\n",
    "        self.test_data = [i + [0] * (self.vector_len - len(i)) for i in\n",
    "                          list(map(lambda vector: vector[:self.vector_len], self.test_data))]\n",
    "        self.train_dataset = MyDataset(data=self.train_data, classes=self.train_classes)\n",
    "        self.test_dataset = MyDataset(data=self.test_data, classes=self.test_classes)\n",
    "\n",
    "    def count_vector_len(self):\n",
    "        max_len = 0\n",
    "        for vector in self.train_data:\n",
    "            max_len = max(max_len, len(vector))\n",
    "        return max_len\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    @property\n",
    "    def num_inputs(self):\n",
    "        if not self.vector_len:\n",
    "            self.vector_len = self.count_vector_len()\n",
    "        return self.vector_len\n",
    "\n",
    "    @property\n",
    "    def num_outputs(self):\n",
    "        return self.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training SNN\n",
    "- one LIF layer\n",
    "- beta (decay rate) = 0.92\n",
    "- spike threshold = 1\n",
    "- potential subtract after spike emission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "import snntorch as snn\n",
    "import torch.nn.functional as F\n",
    "from snntorch import surrogate\n",
    "\n",
    "\n",
    "class SpikeText(pl.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, beta, num_outputs, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.spike_grad = surrogate.fast_sigmoid()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=self.spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        # Initialize hidden states at t=0\n",
    "        self.mem1 = self.lif1.init_leaky()\n",
    "        self.lr = learning_rate\n",
    "        # self.loss_fct = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x, mem1):\n",
    "        cur1 = self.fc1(x)\n",
    "        spk1, mem1_after = self.lif1(cur1, mem1)\n",
    "        cur2 = self.fc2(spk1)\n",
    "        return cur2, mem1_after\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     spk, mem = self.forward(x)\n",
    "    #     loss = self.loss_fct(mem, y)\n",
    "    #     self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    #     return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx, mem1=None):\n",
    "        if not mem1:\n",
    "            mem1 = self.mem1\n",
    "        x, y = batch\n",
    "        cur, mem1_after = self.forward(x, mem1)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        # self.test_balanced_accuracy(cur, y)\n",
    "        # self.log(\"test_BA\", self.test_balanced_accuracy.compute(), prog_bar=True)\n",
    "        # self.test_balanced_accuracy(cur, y)\n",
    "        # self.log(\"test_F1-score\", self.test_f1_score.compute(), prog_bar=True)\n",
    "        return {'loss': loss, 'mem1': mem1_after}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyDataModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7k/5cn3qjmd02qbrvy6k109rg200000gn/T/ipykernel_65257/3169840567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m ib_data_module = MyDataModule(\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mtrain_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'data/processed/TitleMeshIB/TrainTitleIB.csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mtest_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'data/processed/TitleMeshIB/TestTitleIB.csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'MyDataModule' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "ib_data_module = MyDataModule(\n",
    "    train_path='data/processed/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='data/processed/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='data/processed/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='data/processedTitleMeshIB/TestTitleIBClass.csv'\n",
    ")\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='data/processed/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='data/processed/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='data/processed/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='data/processed/TitleMeshB/TestTitleBClass.csv'\n",
    ")\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='data/processed/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='data/processed/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='data/processed/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='data/processed/20NewsgroupShort/TestShortBydateClass.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model_ng = SpikeText(num_inputs=ng_data_module.num_inputs, num_hidden=1000, beta=0.92,\n",
    "                     num_outputs=ng_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_ib = SpikeText(num_inputs=ib_data_module.num_inputs, num_hidden=1000, beta=0.92,\n",
    "                     num_outputs=ib_data_module.num_outputs, learning_rate=1e-4)\n",
    "model_b = SpikeText(num_inputs=b_data_module.num_inputs, num_hidden=1000, beta=0.92,\n",
    "                    num_outputs=b_data_module.num_outputs, learning_rate=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "ib_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                        max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                        callbacks=[checkpoint_callback])\n",
    "b_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                       max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                       callbacks=[checkpoint_callback])\n",
    "ng_trainer = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                        max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                        callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 20.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf563814833545f0ba7bcb5f14382796"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66ea79783aaa47e599686640ac393e30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | lif1           | Leaky    | 0     \n",
      "2 | fc2            | Linear   | 15.0 K\n",
      "3 | train_accuracy | Accuracy | 0     \n",
      "4 | test_accuracy  | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d447ef5532c4891becccb509c14d779"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_sets = [(model_ng, ng_data_module, ng_trainer), (model_b, b_data_module, b_trainer),\n",
    "                 (model_ib, ib_data_module, ib_trainer)]\n",
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.fit(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aa72962cd164633a3c78f12c947699b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.23975901305675507, 'test_loss': 3.216249465942383}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ed3bf71b04c42939f31cbe462995155"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3863840699195862, 'test_loss': 2.1964197158813477}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bcad8bc43164fdbb304cfbdcc066df2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.3924439251422882, 'test_loss': 2.207373857498169}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model, data_module, trainer in training_sets:\n",
    "    trainer.test(model, datamodule=data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing MLP network:\n",
    "- two layer\n",
    "- sigmoid activation function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "class Perceptron(pl.LightningModule):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, learning_rate, no_class):\n",
    "        super().__init__()\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lr = learning_rate\n",
    "        self.loss_fct = F.cross_entropy\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "        # self.test_balanced_accuracy = torchmetrics.Accuracy(average='micro', num_classes=no_class)\n",
    "        # self.test_f1_score = torchmetrics.F1Score(average='macro', num_classes=no_class);\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        cur1 = self.fc1(x)\n",
    "        cur1 = self.sigmoid(cur1)\n",
    "        cur2 = self.fc2(cur1)\n",
    "        cur2 = self.sigmoid(cur2)\n",
    "        return cur2\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_accuracy(cur, y)\n",
    "        self.log(\"train_acc\", self.train_accuracy.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        cur = self.forward(x)\n",
    "        loss = self.loss_fct(cur, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.test_accuracy(cur, y)\n",
    "        self.log(\"test_acc\", self.test_accuracy.compute(), prog_bar=True)\n",
    "        # self.test_balanced_accuracy(cur, y)\n",
    "        # self.log(\"test_BA\", self.test_balanced_accuracy.compute(), prog_bar=True)\n",
    "        # self.test_f1_score(cur, y)\n",
    "        # self.log(\"test_F1-score\", self.test_f1_score.compute(), prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "ib_data_module = MyDataModule(\n",
    "    train_path='data/processed/TitleMeshIB/TrainTitleIB.csv',\n",
    "    test_path='data/processed/TitleMeshIB/TestTitleIB.csv',\n",
    "    train_classes_path='data/processed/TitleMeshIB/TrainTitleIBClass.csv',\n",
    "    test_classes_path='data/processedTitleMeshIB/TestTitleIBClass.csv'\n",
    ")\n",
    "b_data_module = MyDataModule(\n",
    "    train_path='data/processed/TitleMeshB/TrainTitleB.csv',\n",
    "    test_path='data/processed/TitleMeshB/TestTitleB.csv',\n",
    "    train_classes_path='data/processed/TitleMeshB/TrainTitleBClass.csv',\n",
    "    test_classes_path='data/processed/TitleMeshB/TestTitleBClass.csv'\n",
    ")\n",
    "ng_data_module = MyDataModule(\n",
    "    train_path='data/processed/20NewsgroupShort/TrainShortBydate.csv',\n",
    "    test_path='data/processed/20NewsgroupShort/TestShortBydate.csv',\n",
    "    train_classes_path='data/processed/20NewsgroupShort/TrainShortBydateClass.csv',\n",
    "    test_classes_path='data/processed/20NewsgroupShort/TestShortBydateClass.csv'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 752 K \n",
      "1 | fc2            | Linear   | 20.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "4 | sigmoid        | Sigmoid  | 0     \n",
      "--------------------------------------------\n",
      "772 K     Trainable params\n",
      "0         Non-trainable params\n",
      "772 K     Total params\n",
      "3.088     Total estimated model params size (MB)\n",
      "/Users/piotr/praca/nauka/publikacje/Hierarchical Text Classification/Software/SNNTorch-short-text-classifier/venv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /Users/piotr/praca/nauka/publikacje/Hierarchical Text Classification/Software/SNNTorch-short-text-classifier/lightning_logs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/Users/piotr/praca/nauka/publikacje/Hierarchical Text Classification/Software/SNNTorch-short-text-classifier/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a08b0004fac04521949a07de74c6fa02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotr/praca/nauka/publikacje/Hierarchical Text Classification/Software/SNNTorch-short-text-classifier/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "715c5dd5d583491aaa8ff0e7ca1a84e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.005375939887017012, 'test_loss': 3.132855176925659}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "4 | sigmoid        | Sigmoid  | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12ccb813e8f64f9abf2784ff6d17f084"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7384fa2e7f7c457e9c77da44a16300d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.31856489181518555, 'test_loss': 2.401262044906616}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | fc1            | Linear   | 1.6 M \n",
      "1 | fc2            | Linear   | 15.0 K\n",
      "2 | train_accuracy | Accuracy | 0     \n",
      "3 | test_accuracy  | Accuracy | 0     \n",
      "4 | sigmoid        | Sigmoid  | 0     \n",
      "--------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.484     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e9ea9aedfd64726b568a81eaa92c53c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "431e474520124547b7cb8294d106c7db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.30712130665779114, 'test_loss': 2.400636672973633}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ng_mlp_model = Perceptron(num_inputs=ng_data_module.num_inputs, num_hidden=1000,\n",
    "                          num_outputs=ng_data_module.num_outputs, learning_rate=1e-4,\n",
    "                          no_class=ng_data_module.num_classes)\n",
    "ib_mlp_model = Perceptron(num_inputs=ib_data_module.num_inputs, num_hidden=1000,\n",
    "                          num_outputs=ib_data_module.num_outputs, learning_rate=1e-4,\n",
    "                          no_class=ib_data_module.num_classes)\n",
    "b_mlp_model = Perceptron(num_inputs=b_data_module.num_inputs, num_hidden=1000,\n",
    "                         num_outputs=b_data_module.num_outputs, learning_rate=1e-4, no_class=b_data_module.num_classes)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_acc\",\n",
    "    dirpath='lightning_logs',\n",
    "    filename=\"{epoch:02d}-{train_acc:.2f}\",\n",
    ")\n",
    "mlp_trainer_ib = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                            max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                            callbacks=[checkpoint_callback])\n",
    "mlp_trainer_b = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                           max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                           callbacks=[checkpoint_callback])\n",
    "mlp_trainer_ng = pl.Trainer(default_root_dir='lightning_logs',\n",
    "                            max_epochs=8, gpus=torch.cuda.device_count(),\n",
    "                            callbacks=[checkpoint_callback])\n",
    "\n",
    "mlp_training_sets = [(ng_mlp_model, ng_data_module, mlp_trainer_ng), (ib_mlp_model, ib_data_module, mlp_trainer_ib),\n",
    "                     (b_mlp_model, b_data_module, mlp_trainer_b)]\n",
    "\n",
    "for mlp_model, mlp_data_module, mlp_trainer in mlp_training_sets:\n",
    "    mlp_trainer.fit(mlp_model, datamodule=mlp_data_module)\n",
    "    mlp_trainer.test(mlp_model, datamodule=mlp_data_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing decision tree\n",
    "* split crititerion - Gini index\n",
    "* max depth of tree - none"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT ACC: 0.4374668082846522\n",
      "RESULT ACC: 0.2614879649890591\n",
      "RESULT ACC: 0.25483870967741934\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "    X = data_module.train_data\n",
    "    y = data_module.train_classes\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    pred = clf.predict(data_module.test_data)\n",
    "    print(\"RESULT ACC:\", accuracy_score(data_module.test_classes, pred))\n",
    "\n",
    "    # print(classification_report(data_module.test_classes, pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing logistic regression\n",
    "- max_iter = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 0.5912108337758896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 0.4026258205689278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/piotr/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 0.4032258064516129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "    X = data_module.train_data\n",
    "    y = data_module.train_classes\n",
    "    lrcv = LogisticRegressionCV()\n",
    "    lrcv.fit(X, y)\n",
    "    lrcv_pred = lrcv.predict(data_module.test_data)\n",
    "    print(\"RESULT:\", accuracy_score(data_module.test_classes, lrcv_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and testing SVC\n",
    "* kernel = RBF\n",
    "* C = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: 0.6104620286776421\n",
      "RESULT: 0.3665207877461707\n",
      "RESULT: 0.36989247311827955\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for data_module in [ng_data_module, ib_data_module, b_data_module]:\n",
    "    X = data_module.train_data\n",
    "    y = data_module.train_classes\n",
    "    svc = svm.SVC()\n",
    "    svc.fit(X, y)\n",
    "    svc_pred = svc.predict(data_module.test_data)\n",
    "    print(\"RESULT:\", accuracy_score(data_module.test_classes, svc_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}